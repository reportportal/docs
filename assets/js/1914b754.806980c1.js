"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[652],{19013:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"dashboards-and-widgets/FlakyTestCasesTableTop50","title":"Flaky test cases table (TOP-50)","description":"Track flaky tests that change status between runs. Identify unstable test cases and improve reliability using test automation metrics dashboard.","source":"@site/docs/dashboards-and-widgets/FlakyTestCasesTableTop50.mdx","sourceDirName":"dashboards-and-widgets","slug":"/dashboards-and-widgets/FlakyTestCasesTableTop50","permalink":"/docs/dashboards-and-widgets/FlakyTestCasesTableTop50","draft":false,"unlisted":false,"editUrl":"https://github.com/reportportal/docs/blob/develop/docs/dashboards-and-widgets/FlakyTestCasesTableTop50.mdx","tags":[],"version":"current","sidebarPosition":21,"frontMatter":{"sidebar_position":21,"sidebar_label":"Flaky test cases table (TOP-50)","description":"Track flaky tests that change status between runs. Identify unstable test cases and improve reliability using test automation metrics dashboard."},"sidebar":"docs","previous":{"title":"Passing rate summary","permalink":"/docs/dashboards-and-widgets/PassingRateSummary"},"next":{"title":"Cumulative trend chart","permalink":"/docs/dashboards-and-widgets/CumulativeTrendChart"}}');var n=t(74848),i=t(28453);const o={sidebar_position:21,sidebar_label:"Flaky test cases table (TOP-50)",description:"Track flaky tests that change status between runs. Identify unstable test cases and improve reliability using test automation metrics dashboard."},r="Flaky test cases table (TOP-50)",d={},l=[];function c(e){const s={admonition:"admonition",h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{MediaViewer:a}=s;return a||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("MediaViewer",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.header,{children:(0,n.jsx)(s.h1,{id:"flaky-test-cases-table-top-50",children:"Flaky test cases table (TOP-50)"})}),"\n",(0,n.jsx)(s.p,{children:"Shows the TOP-50 the most flaky test cases within the specified previous launches."}),"\n",(0,n.jsx)(s.p,{children:"The test case is displayed in the table if test case status has changed at least once from Passed to Failed or from Failed to Passed in the specified previous launches."}),"\n",(0,n.jsx)(s.admonition,{type:"note",children:(0,n.jsx)(s.p,{children:"For the Flaky Test Cases Table Top 50 widget, only the status of the last retry of a test case is considered. If a test case undergoes multiple retries during different launch executions, and the last retries of each launch yield identical statuses, the test case will not be classified as flaky. Thus, for a test to be identified as flaky, the final retry statuses in each launch must differ."})}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.strong,{children:"Widget's parameters:"})}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsx)(s.p,{children:"Launches count: 2-100. The default meaning is 30."}),"\n"]}),"\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsx)(s.p,{children:"Launch name: required filed."}),"\n"]}),"\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsx)(s.p,{children:"Include Before and After methods: optional."}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.strong,{children:"Widget view"})}),"\n",(0,n.jsx)(s.p,{children:"The widget has a table view with the following data displayed:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Test Case - link to the Step level of the last launch."}),"\n",(0,n.jsx)(s.li,{children:"Switches - count of found results with often switches."}),"\n",(0,n.jsx)(s.li,{children:"% of Switches - the percent of the fact switches and the possible."}),"\n",(0,n.jsx)(s.li,{children:"Last switch - date and time of the last run, when the test item switches the status, displayed in \u201ctime ago\u201d format (i.e. \u201c10 minutes ago\u201d)."}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:"On mouse hover, the system will display accurate start times."}),"\n",(0,n.jsx)(s.admonition,{type:"note",children:(0,n.jsx)(s.p,{children:"In \u201cSwitches\u201d column only Passed and Failed statuses are displayed (Passed - green, Failed - red)."})}),"\n",(0,n.jsxs)(s.admonition,{type:"important",children:[(0,n.jsxs)(s.p,{children:["The number of switches from one state to another of the test case with the same uniqueID is displayed in the format ",(0,n.jsx)(s.strong,{children:"N from M"})," where:"]}),(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"N"})," is the number of changes of statuses."]}),(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"M"})," is the number of all possible changes of the item in selection (number of item runs=number of test executions minus number of executions with status Skipped minus 1)."]}),(0,n.jsx)(s.p,{children:"On mouse hover, tooltip appears \u201cN status changes from M possible times\u201d."})]}),"\n",(0,n.jsx)(a,{src:t(94148),alt:"Data visualization in test automation: Flaky Test Cases Table Widget"})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},94148:(e,s,t)=>{t.r(s),t.d(s,{default:()=>a});const a=t.p+"assets/images/FlakyTestCasesTableWidget-79e85e22e1125398eee343deb978e666.png"},28453:(e,s,t)=>{t.d(s,{R:()=>o,x:()=>r});var a=t(96540);const n={},i=a.createContext(n);function o(e){const s=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),a.createElement(i.Provider,{value:s},e.children)}}}]);